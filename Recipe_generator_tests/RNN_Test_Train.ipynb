{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9b81d39",
   "metadata": {},
   "source": [
    "# RNN Test: Recetas de cocina\n",
    "\n",
    "Basado en: https://www.kdnuggets.com/2020/07/generating-cooking-recipes-using-tensorflow.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "391a1592",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:14.458176Z",
     "start_time": "2021-07-26T13:54:10.568890Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import platform\n",
    "import time\n",
    "import pathlib\n",
    "import os\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8b36f57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:15.586399Z",
     "start_time": "2021-07-26T13:54:15.568449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Se esconde la GPU porque al parecer hay problemas con cuDNN y LSTM\n",
    "# https://stackoverflow.com/questions/37660312/how-to-run-tensorflow-on-cpu\n",
    "# https://github.com/mozilla/DeepSpeech/issues/3088\n",
    "# \n",
    "# tf.config.set_visible_devices([], 'GPU')\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = ''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2934e",
   "metadata": {},
   "source": [
    "# Cargar los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e9b1d7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:18.922876Z",
     "start_time": "2021-07-26T13:54:15.854899Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_targeted = tf.data.experimental.load('Dataset_Train', compression='GZIP')\n",
    "with open('Tokenizer.pkl', 'rb') as file:\n",
    "    tokenizer = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b04e7a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:19.938756Z",
     "start_time": "2021-07-26T13:54:19.929780Z"
    }
   },
   "outputs": [],
   "source": [
    "VOCABULARY_SIZE = len(tokenizer.word_counts) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a32a483",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T21:51:48.957675Z",
     "start_time": "2021-07-23T21:51:19.177052Z"
    }
   },
   "source": [
    "# Separar la base de datos en batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "194dd137",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:20.625212Z",
     "start_time": "2021-07-26T13:54:20.602275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<RepeatDataset shapes: ((64, 2000), (64, 2000)), types: (tf.int32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "# Batch size.\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# Buffer size to shuffle the dataset (TF data is designed to work\n",
    "# with possibly infinite sequences, so it doesn't attempt to shuffle\n",
    "# the entire sequence in memory. Instead, it maintains a buffer in\n",
    "# which it shuffles elements).\n",
    "SHUFFLE_BUFFER_SIZE = 1000\n",
    "\n",
    "dataset_train = dataset_targeted.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "\n",
    "print(dataset_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fec5081",
   "metadata": {},
   "source": [
    "# Construir el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f48485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:21.328936Z",
     "start_time": "2021-07-26T13:54:21.085319Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_input_array shape: (2, 8)\n",
      "tmp_input_array:\n",
      "[[9 3 4 9 8 7 7 0]\n",
      " [7 9 5 1 2 4 9 2]]\n",
      "\n",
      "tmp_output_array shape: (2, 8, 5)\n",
      "tmp_output_array:\n",
      "[[[ 0.00891067 -0.02277729 -0.03066033  0.0083333  -0.00823761]\n",
      "  [ 0.03773025  0.0295834  -0.02404933  0.043337    0.01378472]\n",
      "  [-0.00171058 -0.03350209 -0.00853221  0.00702941 -0.004572  ]\n",
      "  [ 0.00891067 -0.02277729 -0.03066033  0.0083333  -0.00823761]\n",
      "  [ 0.00666205  0.0015915  -0.02814863 -0.03730105  0.0387584 ]\n",
      "  [ 0.04477696  0.01274076 -0.00994901 -0.0189967  -0.00352753]\n",
      "  [ 0.04477696  0.01274076 -0.00994901 -0.0189967  -0.00352753]\n",
      "  [-0.01440569  0.01686419 -0.02905114 -0.04770547  0.02911556]]\n",
      "\n",
      " [[ 0.04477696  0.01274076 -0.00994901 -0.0189967  -0.00352753]\n",
      "  [ 0.00891067 -0.02277729 -0.03066033  0.0083333  -0.00823761]\n",
      "  [ 0.00074028 -0.03683481 -0.0330416   0.00641272 -0.01775007]\n",
      "  [-0.01117425 -0.00350052 -0.03661614  0.01532303  0.00987228]\n",
      "  [-0.03477343 -0.01002655  0.00635991 -0.01404545  0.00954934]\n",
      "  [-0.00171058 -0.03350209 -0.00853221  0.00702941 -0.004572  ]\n",
      "  [ 0.00891067 -0.02277729 -0.03066033  0.0083333  -0.00823761]\n",
      "  [-0.03477343 -0.01002655  0.00635991 -0.01404545  0.00954934]]]\n"
     ]
    }
   ],
   "source": [
    "tmp_vocab_size = 10\n",
    "tmp_embedding_size = 5\n",
    "tmp_input_length = 8\n",
    "tmp_batch_size = 2\n",
    "\n",
    "tmp_model = tf.keras.models.Sequential()\n",
    "tmp_model.add(tf.keras.layers.Embedding(\n",
    "  input_dim=tmp_vocab_size,\n",
    "  output_dim=tmp_embedding_size,\n",
    "  input_length=tmp_input_length\n",
    "))\n",
    "# The model will take as input an integer matrix of size (batch, input_length).\n",
    "# The largest integer (i.e. word index) in the input should be no larger than 9 (tmp_vocab_size).\n",
    "# Now model.output_shape == (None, 10, 64), where None is the batch dimension.\n",
    "tmp_input_array = np.random.randint(\n",
    "  low=0,\n",
    "  high=tmp_vocab_size,\n",
    "  size=(tmp_batch_size, tmp_input_length)\n",
    ")\n",
    "tmp_model.compile('rmsprop', 'mse')\n",
    "tmp_output_array = tmp_model.predict(tmp_input_array)\n",
    "\n",
    "print('tmp_input_array shape:', tmp_input_array.shape)\n",
    "print('tmp_input_array:')\n",
    "print(tmp_input_array)\n",
    "print()\n",
    "print('tmp_output_array shape:', tmp_output_array.shape)\n",
    "print('tmp_output_array:')\n",
    "print(tmp_output_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bcaa74",
   "metadata": {},
   "source": [
    "# Modelo LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1602173e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:22.268717Z",
     "start_time": "2021-07-26T13:54:22.101852Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (64, None, 256)           45056     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (64, None, 1024)          3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (64, None, 176)           180400    \n",
      "=================================================================\n",
      "Total params: 4,163,760\n",
      "Trainable params: 4,163,760\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.models.Sequential()\n",
    "\n",
    "    model.add(tf.keras.layers.Embedding(\n",
    "        input_dim=vocab_size,\n",
    "        output_dim=embedding_dim,\n",
    "        batch_input_shape=[batch_size, None]\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.GRU(\n",
    "        units=rnn_units,\n",
    "        return_sequences=True,\n",
    "        stateful=True,\n",
    "        recurrent_initializer=tf.keras.initializers.GlorotNormal()\n",
    "    ))\n",
    "\n",
    "    model.add(tf.keras.layers.Dense(vocab_size))\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(\n",
    "  vocab_size=VOCABULARY_SIZE,\n",
    "  embedding_dim=256,\n",
    "  rnn_units=1024,\n",
    "  batch_size=BATCH_SIZE\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ad816f",
   "metadata": {},
   "source": [
    "# Pruebas del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82b3496f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:35.067326Z",
     "start_time": "2021-07-26T13:54:23.070124Z"
    }
   },
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 1024, 1, 2000, 64, 0]  [Op:CudnnRNN]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\CHRIS-~1\\AppData\\Local\\Temp/ipykernel_21124/3865811579.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0minput_example_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_example_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mexample_batch_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_example_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample_batch_predictions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"# (batch_size, sequence_length, vocab_size)\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    378\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m  \u001b[1;31m# handle the corner case where self.layers is empty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    418\u001b[0m         \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mtensors\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mmore\u001b[0m \u001b[0mthan\u001b[0m \u001b[0mone\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m     \"\"\"\n\u001b[1;32m--> 420\u001b[1;33m     return self._run_internal_graph(\n\u001b[0m\u001b[0;32m    421\u001b[0m         inputs, training=training, mask=mask)\n\u001b[0;32m    422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\functional.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_arguments\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Update tensor_dict.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    667\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minitial_state\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mconstants\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 668\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mRNN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    670\u001b[0m     \u001b[1;31m# If any of `initial_state` or `constants` are specified and are Keras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1028\u001b[0m         with autocast_variable.enable_auto_cast_variables(\n\u001b[0;32m   1029\u001b[0m             self._compute_dtype_object):\n\u001b[1;32m-> 1030\u001b[1;33m           \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1032\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_activity_regularizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, inputs, mask, training, initial_state)\u001b[0m\n\u001b[0;32m    455\u001b[0m       \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_RUNTIME_UNKNOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       last_output, outputs, runtime, states = self._defun_gru_call(\n\u001b[0m\u001b[0;32m    458\u001b[0m           inputs, initial_state, training, mask, row_lengths)\n\u001b[0;32m    459\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36m_defun_gru_call\u001b[1;34m(self, inputs, initial_state, training, mask, sequence_lengths)\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;31m# Under eager context, check the device placement and prefer the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcan_use_gpu\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m           \u001b[0mlast_output\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mruntime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgpu_gru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mgpu_gru_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m           last_output, outputs, new_h, runtime = standard_gru(\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\recurrent_v2.py\u001b[0m in \u001b[0;36mgpu_gru\u001b[1;34m(inputs, init_h, kernel, recurrent_kernel, bias, mask, time_major, go_backwards, sequence_lengths)\u001b[0m\n\u001b[0;32m    688\u001b[0m       \u001b[1;31m# Reverse axis 0 since the input is already convert to time major.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreverse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m     outputs, h, _, _ = gen_cudnn_rnn_ops.CudnnRNN(\n\u001b[0m\u001b[0;32m    691\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m         is_training=True, rnn_mode='gru')\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\util\\tf_export.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    402\u001b[0m           \u001b[1;34m'Please pass these args as kwargs instead.'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m           .format(f=f.__name__, kwargs=f_argspec.args))\n\u001b[1;32m--> 404\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorator_argspec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mf_argspec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn\u001b[1;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name)\u001b[0m\n\u001b[0;32m     96\u001b[0m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 98\u001b[1;33m       return cudnn_rnn_eager_fallback(\n\u001b[0m\u001b[0;32m     99\u001b[0m           \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_c\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnn_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrnn_mode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m           \u001b[0minput_mode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\ops\\gen_cudnn_rnn_ops.py\u001b[0m in \u001b[0;36mcudnn_rnn_eager_fallback\u001b[1;34m(input, input_h, input_c, params, rnn_mode, input_mode, direction, dropout, seed, seed2, is_training, name, ctx)\u001b[0m\n\u001b[0;32m    176\u001b[0m   \u001b[1;34m\"direction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dropout\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"seed\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"seed2\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m   \"is_training\", is_training)\n\u001b[1;32m--> 178\u001b[1;33m   _result = _execute.execute(b\"CudnnRNN\", 4, inputs=_inputs_flat,\n\u001b[0m\u001b[0;32m    179\u001b[0m                              attrs=_attrs, ctx=ctx, name=name)\n\u001b[0;32m    180\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\chris-brota\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Failed to call ThenRnnForward with model config: [rnn_mode, rnn_input_mode, rnn_direction_mode]: 3, 0, 0 , [num_layers, input_size, num_units, dir_count, max_seq_length, batch_size, cell_num_units]: [1, 256, 1024, 1, 2000, 64, 0]  [Op:CudnnRNN]"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset_train.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76935145",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-26T13:54:35.070283Z",
     "start_time": "2021-07-26T13:54:35.070283Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Prediction for the 1st letter of the batch 1st sequense:')\n",
    "print(example_batch_predictions[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fce8f",
   "metadata": {},
   "source": [
    "# Pruebas con `tf.random.categorical`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a6a23",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-26T13:58:49.460Z"
    }
   },
   "outputs": [],
   "source": [
    "# logits is 2-D Tensor with shape [batch_size, num_classes].\n",
    "# Each slice [i, :] represents the unnormalized log-probabilities for all classes.\n",
    "# In the example below we say that the probability for class \"0\"\n",
    "# (element with index 0) is low but the probability for class \"2\" is much higher.\n",
    "tmp_logits = [\n",
    "  [-0.95, 0, 0.95],\n",
    "];\n",
    "\n",
    "# Let's generate 5 samples. Each sample is a class index. Class probabilities \n",
    "# are being taken into account (we expect to see more samples of class \"2\").\n",
    "tmp_samples = tf.random.categorical(\n",
    "    logits=tmp_logits,\n",
    "    num_samples=5\n",
    ")\n",
    "\n",
    "print(tmp_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0973f5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-26T13:58:49.979Z"
    }
   },
   "outputs": [],
   "source": [
    "sampled_indices = tf.random.categorical(\n",
    "    logits=example_batch_predictions[0],\n",
    "    num_samples=1\n",
    ")\n",
    "\n",
    "sampled_indices = tf.squeeze(\n",
    "    input=sampled_indices,\n",
    "    axis=-1\n",
    ").numpy()\n",
    "\n",
    "sampled_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae4310b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:27:03.836050Z",
     "start_time": "2021-07-23T22:27:03.826077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      " 'ðŸ“—   O l d   F a s h i o n e d   O n i o n   R i n g s \\n \\n ðŸ¥• \\n \\n â€¢   1   l a r g e   o n i o n ,   c'\n",
      "\n",
      "Next char prediction:\n",
      " '9 r ? ` L 5 n â€Ÿ â€“ P â€™ ] F ðŸ¥• Â» Ã» w B D t N â…“ \\x95 \\n O t 4 Â» V â…ž J Ãª Ã‰ â‚¬ Ã¤ S â…“ a â„ > m Ã³ a Æ° j d â‚¬ W'\n"
     ]
    }
   ],
   "source": [
    "print('Input:\\n', repr(''.join(tokenizer.sequences_to_texts([input_example_batch[0].numpy()[:50]]))))\n",
    "print()\n",
    "print('Next char prediction:\\n', repr(''.join(tokenizer.sequences_to_texts([sampled_indices[:50]]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e73d62",
   "metadata": {},
   "source": [
    "# Entrenando el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecae619c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:27:04.621869Z",
     "start_time": "2021-07-23T22:27:04.496206Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 2000, 176)  # (batch_size, sequence_length, vocab_size)\n",
      "scalar_loss.shape:       (64, 2000)\n",
      "scalar_loss:       5.170606\n"
     ]
    }
   ],
   "source": [
    "# An objective function.\n",
    "# The function is any callable with the signature scalar_loss = fn(y_true, y_pred).\n",
    "def loss(labels, logits):\n",
    "    entropy = tf.keras.losses.sparse_categorical_crossentropy(\n",
    "      y_true=labels,\n",
    "      y_pred=logits,\n",
    "      from_logits=True\n",
    "    )\n",
    "    \n",
    "    return entropy\n",
    "\n",
    "example_batch_loss = loss(target_example_batch, example_batch_predictions)\n",
    "\n",
    "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "print(\"scalar_loss.shape:      \", example_batch_loss.shape)\n",
    "print(\"scalar_loss:      \", example_batch_loss.numpy().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aed12959",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:27:10.943361Z",
     "start_time": "2021-07-23T22:27:10.928400Z"
    }
   },
   "outputs": [],
   "source": [
    "adam_optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=adam_optimizer,\n",
    "    loss=loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5070f8f7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:27:11.319236Z",
     "start_time": "2021-07-23T22:27:11.307268Z"
    }
   },
   "outputs": [],
   "source": [
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    monitor='loss',\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e18a6c3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:27:11.553519Z",
     "start_time": "2021-07-23T22:27:11.538561Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a checkpoints directory.\n",
    "checkpoint_dir = 'tmp/checkpoints'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt_{epoch}')\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "558f0efc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:27:11.800137Z",
     "start_time": "2021-07-23T22:27:11.786140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCHS:           500\n",
      "INITIAL_EPOCH:    1\n",
      "STEPS_PER_EPOCH:  1500\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 500\n",
    "INITIAL_EPOCH = 1\n",
    "STEPS_PER_EPOCH = 1500\n",
    "\n",
    "print('EPOCHS:          ', EPOCHS)\n",
    "print('INITIAL_EPOCH:   ', INITIAL_EPOCH)\n",
    "print('STEPS_PER_EPOCH: ', STEPS_PER_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d732d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-07-23T22:27:12.114Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/500\n",
      "   2/1500 [..............................] - ETA: 29:40:43 - loss: 4.9623"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=dataset_train,\n",
    "    epochs=EPOCHS,steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    initial_epoch=INITIAL_EPOCH,\n",
    "    callbacks=[checkpoint_callback, early_stopping_callback],\n",
    "    verbose=1)\n",
    "\n",
    "# Saving the trained model to file (to be able to re-use it later).\n",
    "model_name = 'recipe_generation_rnn_raw.h5'\n",
    "model.save(model_name, save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37741883",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-23T22:36:15.902366Z",
     "start_time": "2021-07-23T22:36:15.881421Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1789427665321178190\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1996200347\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 3093676066046094884\n",
      "physical_device_desc: \"device: 0, name: NVIDIA GeForce GTX 1050, pci bus id: 0000:01:00.0, compute capability: 6.1\"\n",
      "]\n",
      "Default GPU Device: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b904d0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 401,
   "position": {
    "height": "435px",
    "left": "1266px",
    "right": "20px",
    "top": "102px",
    "width": "411px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
